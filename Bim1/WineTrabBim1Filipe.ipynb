{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "WineTrabBim1Filipe.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Krufg2DqMZad",
        "colab_type": "text"
      },
      "source": [
        "# Exemplo de implementação de rede neural low-level.\n",
        "Base de dados utilizada iris do lib sklearn.\n",
        "\n",
        "Problema multi-classes utilizando a função de ativação SOFTMAX\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpZvqV3vMZae",
        "colab_type": "code",
        "outputId": "a3f4632c-eb8c-4a16-cb32-f0efd0a99301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# importação da lib sklearn importando os datasets\n",
        "# repositório: archive.ics.uci.edu/ml/datasets/Iris\n",
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "# vamos usar o exemplo iris()\n",
        "wine = datasets.load_wine()\n",
        "# atributos previsores (4 características)\n",
        "X = wine.data\n",
        "X"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
              "        1.065e+03],\n",
              "       [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
              "        1.050e+03],\n",
              "       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
              "        1.185e+03],\n",
              "       ...,\n",
              "       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
              "        8.350e+02],\n",
              "       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
              "        8.400e+02],\n",
              "       [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
              "        5.600e+02]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt3CR3JKMZaj",
        "colab_type": "code",
        "outputId": "7548d311-c83f-4e2a-ec1f-9752225349be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# atributos das classes\n",
        "y = wine.target\n",
        "y"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zxeo_yhOMZan",
        "colab_type": "code",
        "outputId": "5978063e-2598-42e7-b848-4c83d822355d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# padronização dos dados\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler_x = StandardScaler()\n",
        "X = scaler_x.fit_transform(X)\n",
        "X = np.float32(X)\n",
        "X =  np.delete(X, 2, 1)\n",
        "X =  np.delete(X, 2, 1)\n",
        "X =  np.delete(X, 2, 1)\n",
        "X =  np.delete(X, 2, 1)\n",
        "X =  np.delete(X, 2, 1)\n",
        "X =  np.delete(X, 2, 1)\n",
        "X =  np.delete(X, 2, 1)\n",
        "X =  np.delete(X, 3, 1)\n",
        "X =  np.delete(X, 2, 1)\n",
        "# Alcohol Malic acid Color intensity Proline\n",
        "X"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.5186125 , -0.5622498 ,  1.8479196 ,  1.013009  ],\n",
              "       [ 0.24628963, -0.49941337,  1.1134493 ,  0.9652415 ],\n",
              "       [ 0.19687903,  0.02123125,  0.78858745,  1.3951482 ],\n",
              "       [ 1.6915497 , -0.34681064,  1.1840714 ,  2.3345737 ],\n",
              "       [ 0.29570022,  0.22769377,  0.44960117, -0.03787401],\n",
              "       [ 1.4815546 , -0.51736665,  0.33660576,  2.239039  ],\n",
              "       [ 1.716255  , -0.4186237 ,  1.367689  ,  1.72952   ],\n",
              "       [ 1.3086175 , -0.16727802,  1.367689  ,  1.7454425 ],\n",
              "       [ 2.2597716 , -0.62508625,  0.33660576,  0.94931906],\n",
              "       [ 1.0615644 , -0.8854085 ,  1.3253157 ,  0.94931906],\n",
              "       [ 1.358028  , -0.15830138,  0.78858745,  2.4301085 ],\n",
              "       [ 1.3827333 , -0.76871234,  0.29423246,  1.6976751 ],\n",
              "       [ 0.92568535, -0.54429656,  0.4072279 ,  1.8250549 ],\n",
              "       [ 2.1609504 , -0.54429656,  0.16711262,  1.2836909 ],\n",
              "       [ 1.7039022 , -0.4186237 ,  0.54847217,  2.547935  ],\n",
              "       [ 0.77745354, -0.4724835 ,  0.37897903,  1.7932099 ],\n",
              "       [ 1.6050811 , -0.37374052,  0.05411719,  1.6976751 ],\n",
              "       [ 1.0245066 , -0.68792266, -0.05887824,  1.220001  ],\n",
              "       [ 1.4692019 , -0.6699694 ,  0.29423246,  2.9714725 ],\n",
              "       [ 0.7898062 ,  0.685502  ,  1.0569516 ,  0.3124203 ],\n",
              "       [ 1.3086175 , -0.6340628 ,  1.5513066 ,  0.10542821],\n",
              "       [-0.08723191,  1.3138661 ,  1.2829424 ,  0.07358328],\n",
              "       [ 0.87627476, -0.42760032,  1.960915  ,  0.9174741 ],\n",
              "       [-0.18605311, -0.66099274,  1.4383111 ,  0.85378426],\n",
              "       [ 0.6168691 , -0.4724835 ,  1.7066753 ,  0.3124203 ],\n",
              "       [ 0.06099989, -0.25704432,  0.83096075,  0.2646529 ],\n",
              "       [ 0.48098996, -0.50839   ,  0.8592096 ,  1.4269931 ],\n",
              "       [ 0.36981612, -0.55327314,  0.22361033,  1.7135975 ],\n",
              "       [ 1.0739172 , -0.3916938 ,  1.1134493 ,  0.5353349 ],\n",
              "       [ 1.2592069 , -0.5891797 ,  1.3818134 ,  0.9174741 ],\n",
              "       [ 0.90098006, -0.75075907,  0.13886376,  1.7135975 ],\n",
              "       [ 0.7156903 , -0.607133  ,  0.37897903,  2.446031  ],\n",
              "       [ 0.8392168 , -0.4545302 ,  0.3648546 ,  0.7741719 ],\n",
              "       [ 0.938038  , -0.72382915,  0.54847217,  1.5543729 ],\n",
              "       [ 0.62922174, -0.48146012,  0.3648546 ,  1.1085438 ],\n",
              "       [ 0.5921638 , -0.4724835 ,  1.2123203 ,  0.5512573 ],\n",
              "       [ 0.34511083, -0.62508625,  0.23773475,  0.4238776 ],\n",
              "       [ 0.06099989, -0.6161096 , -0.1436248 ,  1.1403887 ],\n",
              "       [ 0.08570518, -0.75075907,  0.1106149 ,  0.8697067 ],\n",
              "       [ 1.5062599 ,  1.4844222 ,  1.2970669 ,  0.04173834],\n",
              "       [ 0.690985  , -0.5622498 ,  1.0852004 ,  0.15319562],\n",
              "       [ 0.5056953 ,  1.3497727 ,  0.54847217,  0.9174741 ],\n",
              "       [ 1.0862699 , -0.40067044,  1.3394401 ,  1.1085438 ],\n",
              "       [ 0.29570022,  1.4754455 ,  0.54847217, -0.21302116],\n",
              "       [ 0.06099989, -0.50839   ,  1.0428271 ,  0.43980005],\n",
              "       [ 1.4939072 ,  1.5293053 ,  1.0145783 ,  1.0607764 ],\n",
              "       [ 1.7039022 ,  1.1253569 ,  1.169947  ,  1.013009  ],\n",
              "       [ 1.1109751 , -0.5891797 ,  1.0145783 ,  0.7582494 ],\n",
              "       [ 1.358028  , -0.28397423,  0.19536147,  0.99708647],\n",
              "       [ 1.1603857 , -0.54429656,  0.68971646,  1.6339852 ],\n",
              "       [ 0.06099989, -0.54429656,  0.42135233,  1.2836909 ],\n",
              "       [ 1.0245066 , -0.6161096 ,  1.071076  ,  1.6499077 ],\n",
              "       [ 1.0121539 , -0.5263433 ,  0.9157073 ,  1.4110706 ],\n",
              "       [ 0.95039064, -0.3916938 ,  0.44960117,  2.000202  ],\n",
              "       [ 0.9133327 , -0.59815633,  0.83096075,  0.99708647],\n",
              "       [ 0.690985  , -0.54429656,  0.59084547,  1.1881561 ],\n",
              "       [ 1.5062599 , -0.5712264 ,  0.98632944,  0.710482  ],\n",
              "       [ 0.35746348, -0.3288574 ,  0.32248133,  1.6658301 ],\n",
              "       [ 0.8886274 , -0.8135955 ,  0.3648546 ,  1.7135975 ],\n",
              "       [-0.7789803 , -1.2534504 , -1.1182103 , -0.72254014],\n",
              "       [-0.8283909 , -1.1098243 , -1.3300768 , -0.21302116],\n",
              "       [-0.44545874, -0.8764319 , -1.4430722 , -0.9454547 ],\n",
              "       [ 0.8268642 , -0.97517484, -0.21424694, -0.37224585],\n",
              "       [-0.7789803 , -1.0828944 ,  0.3648546 , -1.0409895 ],\n",
              "       [-1.0260333 , -0.7956422 , -0.5391088 , -1.2479817 ],\n",
              "       [-0.7789803 , -1.0110813 , -0.4402378 , -0.21939015],\n",
              "       [ 0.13511579, -1.190614  ,  0.8027119 , -0.77986103],\n",
              "       [-0.7789803 , -1.0469879 ,  1.2264447 , -0.7543851 ],\n",
              "       [ 0.41922674, -1.2534504 , -0.96284163,  0.0098934 ],\n",
              "       [-0.9766227 , -1.0290346 ,  0.64734316, -0.0920104 ],\n",
              "       [-0.8778015 , -0.6520161 , -1.1182103 ,  0.39203265],\n",
              "       [ 1.0615644 , -0.7417824 ,  0.774463  , -1.0728345 ],\n",
              "       [ 0.60451645, -0.607133  ,  0.23773475, -0.87539583],\n",
              "       [-0.01311601, -0.59815633,  1.2546936 ,  0.7582494 ],\n",
              "       [-1.2854389 , -1.118801  ,  0.73208976,  0.44298455],\n",
              "       [-1.6560184 , -0.40964708, -0.66622865, -1.0155135 ],\n",
              "       [ 0.03629459, -1.289357  , -0.18599808, -1.1301553 ],\n",
              "       [-1.4336708 ,  0.4969927 , -0.12950037, -0.78623   ],\n",
              "       [-0.8283909 , -1.2085673 , -0.42611337,  0.0098934 ],\n",
              "       [-0.37134287,  1.3767025 ,  0.73208976, -0.9040563 ],\n",
              "       [-1.2360283 , -1.2714037 ,  0.7179653 , -1.4931877 ],\n",
              "       [-0.34663755, -0.4724835 ,  0.74621415, -0.10474838],\n",
              "       [-1.1372072 , -1.0828944 ,  0.1529882 , -0.37224585],\n",
              "       [ 0.06099989,  1.367726  , -0.8498462 , -0.7384626 ],\n",
              "       [-1.4336708 , -1.2983335 ,  0.6614676 , -0.72254014],\n",
              "       [-0.4084008 , -1.2175438 ,  0.774463  , -0.9454547 ],\n",
              "       [-1.038386  , -0.6520161 , -0.4967355 , -0.8021525 ],\n",
              "       [-1.6683711 , -0.59815633,  0.84508514, -0.58879143],\n",
              "       [-1.6807237 , -0.24806769,  0.19536147, -0.21302116],\n",
              "       [-1.1372072 , -0.9033618 ,  0.84508514, -0.3881683 ],\n",
              "       [-1.1372072 , -0.4545302 , -0.4826111 , -0.8499199 ],\n",
              "       [-1.2360283 , -0.7417824 ,  0.05411719, -0.9454547 ],\n",
              "       [-0.3836955 , -0.72382915, -0.7792241 , -0.8021525 ],\n",
              "       [-0.8778015 ,  0.44313294,  0.97220504, -1.4549737 ],\n",
              "       [-1.7054291 , -0.31090412,  0.49197447, -1.2798265 ],\n",
              "       [-0.6554538 , -0.7328058 ,  0.02586833,  0.6053937 ],\n",
              "       [-1.4707286 , -0.1942079 , -0.4967355 , -0.3881683 ],\n",
              "       [-0.8778015 , -0.83154875,  0.18123704, -1.0155135 ],\n",
              "       [-0.7789803 , -1.1367542 ,  0.22361033, -0.27671105],\n",
              "       [-0.8778015 ,  0.7483384 ,  0.3083569 , -1.0855725 ],\n",
              "       [-1.1372072 , -0.23011443,  0.49197447, -0.11748635],\n",
              "       [-0.49486935, -0.89438516,  0.22361033, -0.58879143],\n",
              "       [-0.81603825,  0.10202093,  1.0852004 , -0.9836686 ],\n",
              "       [-1.458376  , -0.55327314, -0.2424958 , -1.056912  ],\n",
              "       [-0.6060432 , -0.54429656,  1.3535646 , -0.23849711],\n",
              "       [-0.717217  ,  0.19178724,  0.97220504, -1.3753613 ],\n",
              "       [-0.9272121 , -0.54429656,  0.78858745, -0.7543851 ],\n",
              "       [-0.34663755, -0.5263433 , -0.27074465, -0.82444394],\n",
              "       [-0.96427006, -0.9392683 ,  0.576721  , -1.3849149 ],\n",
              "       [-1.7177817 , -0.8854085 ,  0.9157073 , -0.21302116],\n",
              "       [-1.9030714 ,  1.2600064 ,  0.28010803, -0.58879143],\n",
              "       [-0.5936906 ,  0.08406767,  0.23773475, -1.3435165 ],\n",
              "       [-1.5324919 ,  0.30848345, -0.15774924, -0.4454892 ],\n",
              "       [-1.9648347 , -1.432983  , -0.42611337, -0.9964066 ],\n",
              "       [-1.1372072 , -0.849502  ,  0.8168363 , -1.1524469 ],\n",
              "       [-2.4342353 , -0.7417824 ,  0.3648546 , -1.0823879 ],\n",
              "       [-1.458376  , -0.777689  ,  1.0145783 , -0.8021525 ],\n",
              "       [-0.717217  , -0.6520161 ,  0.49197447, -1.2798265 ],\n",
              "       [-0.28487432,  0.9817308 , -0.6944775 , -1.1938453 ],\n",
              "       [-1.2360283 ,  0.9817308 ,  0.6190943 , -0.58242244],\n",
              "       [-1.9154241 ,  0.05713777,  1.0993248 , -0.3881683 ],\n",
              "       [-1.779545  , -0.25704432,  1.5230577 , -0.8976873 ],\n",
              "       [-0.717217  ,  1.8793939 ,  0.7179653 , -1.2161367 ],\n",
              "       [ 0.06099989,  3.1091924 ,  0.68971646, -1.1683693 ],\n",
              "       [-1.3966128 ,  1.7716744 ,  1.4524356 , -1.1683693 ],\n",
              "       [-1.1495597 , -0.15830138,  0.94395614, -1.1747383 ],\n",
              "       [-0.7048644 , -0.72382915,  0.32248133, -1.2575351 ],\n",
              "       [-1.4954339 , -0.18523128, -0.2424958 , -0.8945028 ],\n",
              "       [-0.7789803 , -0.6340628 ,  0.23773475, -1.2893801 ],\n",
              "       [-1.1866177 ,  1.7626977 , -0.05887824, -0.53147054],\n",
              "       [-0.17370047, -0.8854085 , -1.8668051 , -0.37224585],\n",
              "       [-0.14899516,  0.58675903, -1.6831875 , -0.6906952 ],\n",
              "       [-0.23546371, -0.02365191, -1.7679341 , -0.5951604 ],\n",
              "       [-0.37134287,  1.0894504 , -1.8668051 , -0.46778065],\n",
              "       [-0.6060432 , -0.9841515 , -1.5560676 , -0.30855596],\n",
              "       [-0.49486935,  0.11099756, -1.4571966 , -0.16525376],\n",
              "       [-0.9272121 ,  2.1397164 , -1.8950539 , -0.08564141],\n",
              "       [-0.5813379 ,  2.84887   , -1.3018279 , -0.7384626 ],\n",
              "       [ 0.60451645,  1.1253569 , -1.1182103 , -0.53147054],\n",
              "       [-0.19840576,  0.5598291 , -0.6521042 , -0.4996256 ],\n",
              "       [-0.08723191,  0.42517966, -0.42611337, -0.46778065],\n",
              "       [ 0.44393203,  0.20076388, -0.20012252,  0.10542821],\n",
              "       [ 0.64157444,  0.7483384 , -0.7792241 , -0.72254014],\n",
              "       [ 0.7651009 ,  2.3461788 , -0.7933485 , -0.62700534],\n",
              "       [-0.9272121 ,  1.3856792 , -0.86397064,  0.34426525],\n",
              "       [ 0.19687903,  1.1074036 , -1.3159523 ,  0.2646529 ],\n",
              "       [ 1.0862699 ,  2.4269686 , -1.8103074 , -1.056912  ],\n",
              "       [-0.1613478 ,  2.0409734 , -1.0617126 , -0.3881683 ],\n",
              "       [ 0.39452142,  0.8111748 , -1.4006989 , -0.30855596],\n",
              "       [ 0.09805783,  1.4036325 , -1.8103074 , -0.62700534],\n",
              "       [ 0.6168691 ,  0.7034552 , -1.8526806 , -0.78623   ],\n",
              "       [-0.260169  ,  0.2995068 , -1.6125653 , -0.8499199 ],\n",
              "       [ 0.13511579, -0.3916938 , -1.8103074 , -1.0250671 ],\n",
              "       [ 0.28334758,  0.8650346 , -1.5560676 , -0.22894363],\n",
              "       [-0.51957464, -0.9392683 , -1.4995699 , -0.3404009 ],\n",
              "       [ 0.20923167,  2.5616179 , -1.5984409 , -0.06971894],\n",
              "       [ 1.0368592 ,  1.6011183 , -1.37245   , -0.8499199 ],\n",
              "       [-0.6801591 ,  0.6226655 , -1.2453302 ,  0.4238776 ],\n",
              "       [ 1.6544917 , -0.5891797 , -0.92046833, -0.27671105],\n",
              "       [ 0.5921638 , -0.59815633, -1.174708  , -0.4040908 ],\n",
              "       [-0.79133296,  1.3407961 , -1.4571966 , -0.72254014],\n",
              "       [ 0.8515695 ,  0.8291281 , -1.1182103 , -0.21302116],\n",
              "       [-0.18605311,  0.8381047 , -0.70860195, -0.56331545],\n",
              "       [-0.05017396,  0.9996841 , -1.2170813 , -0.22894363],\n",
              "       [ 0.9627433 ,  0.3802965 , -1.3159523 , -0.42001325],\n",
              "       [ 0.90098006,  1.8165575 , -1.2170813 , -0.72254014],\n",
              "       [ 0.55510587,  1.2240999 , -1.4854455 , -0.16525376],\n",
              "       [-0.22311106,  0.92787105, -1.2170813 , -0.19709869],\n",
              "       [ 0.7156903 ,  0.21871714, -1.1464592 ,  0.0098934 ],\n",
              "       [ 0.4933426 ,  2.0319967 , -0.9769661 , -0.37224585],\n",
              "       [-0.98897535,  0.6226655 , -1.1040859 , -0.7543851 ],\n",
              "       [-0.28487432,  0.04816114, -1.3865745 , -0.8817648 ],\n",
              "       [ 1.432144  ,  0.15588072, -1.273579  , -0.27671105],\n",
              "       [ 0.87627476,  2.974543  , -1.2312058 , -0.02195154],\n",
              "       [ 0.4933426 ,  1.4126091 , -1.4854455 ,  0.0098934 ],\n",
              "       [ 0.3327582 ,  1.7447445 , -1.4854455 ,  0.28057536],\n",
              "       [ 0.20923167,  0.22769377, -1.4006989 ,  0.29649782],\n",
              "       [ 1.395086  ,  1.5831652 , -1.4289478 , -0.5951604 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6ToDV9bMmKu",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1bCs3lSCjjfJet-cQhoRIvgvXshAE--Rz)\n",
        "\n",
        "Como nosso exemplo tem 3 classes como resposta, precisamos de 3 neurônios de saída"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytX0S9K3MZat",
        "colab_type": "code",
        "outputId": "75f2ed0c-16c3-4570-cdeb-fb136f363a3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# precisamos compatibilizar o numero de registros de saída com a quantidade de classes esperadas.\n",
        "# para isso iremos utilizar o comando OneHotEncoder para que cada resposta tenha 3 atributos, que seja igual \n",
        "# a quantidade de neurônios na camada de saída.\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# passo como parametrao qual coluna quermos fazer a transformação.\n",
        "# instancio um objeto.\n",
        "onehot = OneHotEncoder()\n",
        "y.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(178,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31LgjhJoMZaw",
        "colab_type": "code",
        "outputId": "951523e8-407c-4ebd-ffd2-57692b0d1447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# transformando a resposta em formato de matriz\n",
        "y = y.reshape(-1,1)\n",
        "y.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(178, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIgZERx4MZaz",
        "colab_type": "code",
        "outputId": "bc9ac1b8-70ea-47d3-d787-dedf10b96fc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "onehot.fit(y)\n",
        "y = onehot.transform(y).toarray()\n",
        "y"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAOp07GjMZa2",
        "colab_type": "text"
      },
      "source": [
        "# agora temos as 3 classes representadas por codificação\n",
        "classe 1 -> 1 0 0\n",
        "\n",
        "classe 2 -> 0 1 0\n",
        "\n",
        "classe 3 -> 0 0 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5awxjDxyMZa3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# divisão da base em treinamento (70%) e teste (30%).\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(X, y, test_size = 0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZaaN6IAMZa5",
        "colab_type": "code",
        "outputId": "08518389-555f-4c6f-e4a0-3b0e4398580c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# conferindo a quantidade de regitros.\n",
        "X_treinamento.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(124, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7dQp3FFMZa8",
        "colab_type": "code",
        "outputId": "df628bf9-f04e-47d1-adaf-88b9d2d68433",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# conferindo a quantidade de regitros.\n",
        "X_teste.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX8IAgBYMZa_",
        "colab_type": "code",
        "outputId": "01f4ee05-db43-4ee0-e7fa-83d89e0fa36d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# importação do TensorFlow\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "# importação do NumPy\n",
        "import numpy as np\n",
        "tf.__version__"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl_2g2NIMZbC",
        "colab_type": "code",
        "outputId": "6ae0b376-522e-485e-d2ff-6b2706556b2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# quantidade dos neurônios\n",
        "# para a entrada o num. de neurônios é a quantidade de atributos.\n",
        "neuronios_entrada = X.shape\n",
        "neuronios_entrada"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(178, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S41-gSoRMZbF",
        "colab_type": "code",
        "outputId": "3278f29d-a0d7-40fb-fa89-c20898ca6195",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# para a camada oculta\n",
        "# podemos criar a quantidade baseado no calculo\n",
        "# (quantidade de atributos previsores + quantidade de classes) / 2\n",
        "# np.ceil arredonda para cima\n",
        "neuronios_oculta = int(np.ceil((X.shape[1] + y.shape[1]) / 2))\n",
        "neuronios_oculta"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lD0Lja2MZbH",
        "colab_type": "code",
        "outputId": "510b8e7b-6b58-4a66-dfbb-31c34e0c3bda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# neurônios na camada de saída que é igual ao num. de classes\n",
        "neuronios_saida = y.shape[1]\n",
        "neuronios_saida"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHngreLRMZbJ",
        "colab_type": "text"
      },
      "source": [
        "![Modelo de RNA](https://drive.google.com/uc?id=1bCs3lSCjjfJet-cQhoRIvgvXshAE--Rz)\n",
        "\n",
        "Modelo da RNA\n",
        "<!-- ![Modelo da RNA](RNA2.png) -->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaznEQW2MZbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# criar os pesos, usamos uma estrutura de dados com keys\n",
        "# para a camada oculta precisamos de uma matriz de 4 x 4 = 16 pesos.\n",
        "# para a camada saída precisamos de uma matriz de 4 x 3 = 12 pesos.\n",
        "# os valores do peso são criados com a função RANDOM.\n",
        "\n",
        "W = {'oculta': tf.Variable(tf.random_normal([4, 4])),\n",
        "    'saida': tf.Variable(tf.random_normal([4, neuronios_saida]))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY-I9MeWMZbO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pesos para a unidade de bias\n",
        "# para a camada oculta teremos 4 pesos\n",
        "# para a camada saída teremos 3 pesos.\n",
        "b = {'oculta': tf.Variable(tf.random_normal([4])),\n",
        "     'saida': tf.Variable(tf.random_normal([neuronios_saida]))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp5wIyhyMZbQ",
        "colab_type": "text"
      },
      "source": [
        "![Modelo da RNA](https://drive.google.com/uc?id=1_-_xgpimyQ-R1TReFQrN0k7c3RjqDE28)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKPmkx6IMZbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# criamos os places holders para X, com quantidade indefinida de linha e com 4 colunas\n",
        "xph = tf.placeholder('float', [None, 4])\n",
        "# criamos os places holders para Y, com quantidade indefinida de linha e com 3 colunas\n",
        "yph = tf.placeholder('float', [None, neuronios_saida])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwKXvlm_MZbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# criamos um função para facilitar na reutilização do códigos para testes.\n",
        "# nesta função faremos os calculos do somatório dos peso, o calculo da função de ativação\n",
        "# para as camadas da nossa rede.\n",
        "def funRNA(x, W, bias):\n",
        "    # somatório da camada oculta\n",
        "    camada_oculta = tf.add(tf.matmul(x, W['oculta']), bias['oculta']) \n",
        "    # calculo func. ativação RELU\n",
        "    camada_oculta_ativacao = tf.nn.relu(camada_oculta) \n",
        "    # somatório da camada de saída.\n",
        "    camada_saida = tf.add(tf.matmul(camada_oculta_ativacao, W['saida']), b['saida']) \n",
        "    # retorno dos valores da camada oculta.\n",
        "    return camada_saida"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkoGqPDyMZbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# criamos um modelo que irá enviar como parametros para a func. os valores de pesos e as entradas da rede.\n",
        "# esperamos como saída o calculo dos valores do somatório da camada de saída.\n",
        "modelo = funRNA(xph, W, b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kgx-TnfMZbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# aqui faremos o calculo da função de ativação junto com o calculo do erro.\n",
        "# estamos usando a função SOFTMAX como função de ativação neste modelo.\n",
        "# para que a função faça o calculo do erro, precisamos passar como paramentros os valores\n",
        "# que foram calculados pela rede (modelo) e os valores corretor (yph)\n",
        "# modelo -> respostas que o modelo fez a previsão\n",
        "# yph -> respostas corretas, vetor Y.\n",
        "# func. reduce_mean faz a média do batch inteiro.\n",
        "erro = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = modelo, labels = yph))\n",
        "# vamos criar o otimizados, usando a função ADAM, que é similar ao gradiente de descida.\n",
        "# passamos como parametro o erro, para que seja feita a otimização desse erro.\n",
        "otimizador = tf.train.AdamOptimizer(learning_rate = 0.01).minimize(erro)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OImgZzQKMZba",
        "colab_type": "code",
        "outputId": "25491e21-cd9d-40b5-a6e0-3c0687758f42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# tamanho da atualização dos registros.\n",
        "batch_size = 8\n",
        "batch_total = int(len(X_treinamento) / batch_size)\n",
        "batch_total"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqzTkyAOMZbc",
        "colab_type": "code",
        "outputId": "0d943a89-2544-4e6b-c6df-57a8a3a7439b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# separa o vetor treinamento em 13 partes.\n",
        "X_batches = np.array_split(X_treinamento, batch_total)\n",
        "X_batches"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 0.7898062 ,  0.685502  ,  1.0569516 ,  0.3124203 ],\n",
              "        [-1.1372072 , -0.849502  ,  0.8168363 , -1.1524469 ],\n",
              "        [ 0.8886274 , -0.8135955 ,  0.3648546 ,  1.7135975 ],\n",
              "        [-1.9154241 ,  0.05713777,  1.0993248 , -0.3881683 ],\n",
              "        [-0.08723191,  0.42517966, -0.42611337, -0.46778065],\n",
              "        [ 0.29570022,  0.22769377,  0.44960117, -0.03787401],\n",
              "        [-1.458376  , -0.55327314, -0.2424958 , -1.056912  ],\n",
              "        [-0.7789803 , -1.0469879 ,  1.2264447 , -0.7543851 ],\n",
              "        [ 1.5062599 , -0.5712264 ,  0.98632944,  0.710482  ]],\n",
              "       dtype=float32),\n",
              " array([[ 0.28334758,  0.8650346 , -1.5560676 , -0.22894363],\n",
              "        [ 0.5056953 ,  1.3497727 ,  0.54847217,  0.9174741 ],\n",
              "        [ 0.690985  , -0.54429656,  0.59084547,  1.1881561 ],\n",
              "        [-1.7054291 , -0.31090412,  0.49197447, -1.2798265 ],\n",
              "        [-0.22311106,  0.92787105, -1.2170813 , -0.19709869],\n",
              "        [ 0.92568535, -0.54429656,  0.4072279 ,  1.8250549 ],\n",
              "        [-0.49486935,  0.11099756, -1.4571966 , -0.16525376],\n",
              "        [ 0.9627433 ,  0.3802965 , -1.3159523 , -0.42001325],\n",
              "        [ 0.7156903 ,  0.21871714, -1.1464592 ,  0.0098934 ]],\n",
              "       dtype=float32),\n",
              " array([[-0.8283909 , -1.2085673 , -0.42611337,  0.0098934 ],\n",
              "        [-1.779545  , -0.25704432,  1.5230577 , -0.8976873 ],\n",
              "        [-0.18605311, -0.66099274,  1.4383111 ,  0.85378426],\n",
              "        [-0.08723191,  1.3138661 ,  1.2829424 ,  0.07358328],\n",
              "        [-0.4084008 , -1.2175438 ,  0.774463  , -0.9454547 ],\n",
              "        [-1.038386  , -0.6520161 , -0.4967355 , -0.8021525 ],\n",
              "        [-0.9272121 ,  1.3856792 , -0.86397064,  0.34426525],\n",
              "        [ 1.3086175 , -0.6340628 ,  1.5513066 ,  0.10542821],\n",
              "        [ 1.5062599 ,  1.4844222 ,  1.2970669 ,  0.04173834]],\n",
              "       dtype=float32),\n",
              " array([[-1.4954339 , -0.18523128, -0.2424958 , -0.8945028 ],\n",
              "        [ 1.6544917 , -0.5891797 , -0.92046833, -0.27671105],\n",
              "        [-0.7789803 , -1.0110813 , -0.4402378 , -0.21939015],\n",
              "        [-0.717217  , -0.6520161 ,  0.49197447, -1.2798265 ],\n",
              "        [ 1.1603857 , -0.54429656,  0.68971646,  1.6339852 ],\n",
              "        [-0.9272121 ,  2.1397164 , -1.8950539 , -0.08564141],\n",
              "        [ 1.3086175 , -0.16727802,  1.367689  ,  1.7454425 ],\n",
              "        [-0.8778015 , -0.83154875,  0.18123704, -1.0155135 ],\n",
              "        [ 0.5921638 , -0.59815633, -1.174708  , -0.4040908 ]],\n",
              "       dtype=float32),\n",
              " array([[ 1.358028  , -0.15830138,  0.78858745,  2.4301085 ],\n",
              "        [ 0.60451645, -0.607133  ,  0.23773475, -0.87539583],\n",
              "        [ 0.60451645,  1.1253569 , -1.1182103 , -0.53147054],\n",
              "        [-0.7789803 , -0.6340628 ,  0.23773475, -1.2893801 ],\n",
              "        [-0.260169  ,  0.2995068 , -1.6125653 , -0.8499199 ],\n",
              "        [ 0.6168691 ,  0.7034552 , -1.8526806 , -0.78623   ],\n",
              "        [-0.3836955 , -0.72382915, -0.7792241 , -0.8021525 ],\n",
              "        [ 0.6168691 , -0.4724835 ,  1.7066753 ,  0.3124203 ]],\n",
              "       dtype=float32),\n",
              " array([[ 0.35746348, -0.3288574 ,  0.32248133,  1.6658301 ],\n",
              "        [-0.14899516,  0.58675903, -1.6831875 , -0.6906952 ],\n",
              "        [-0.28487432,  0.04816114, -1.3865745 , -0.8817648 ],\n",
              "        [ 1.6915497 , -0.34681064,  1.1840714 ,  2.3345737 ],\n",
              "        [ 0.13511579, -1.190614  ,  0.8027119 , -0.77986103],\n",
              "        [-0.49486935, -0.89438516,  0.22361033, -0.58879143],\n",
              "        [-0.717217  ,  1.8793939 ,  0.7179653 , -1.2161367 ],\n",
              "        [-2.4342353 , -0.7417824 ,  0.3648546 , -1.0823879 ]],\n",
              "       dtype=float32),\n",
              " array([[-1.6560184 , -0.40964708, -0.66622865, -1.0155135 ],\n",
              "        [ 1.4939072 ,  1.5293053 ,  1.0145783 ,  1.0607764 ],\n",
              "        [-0.28487432,  0.9817308 , -0.6944775 , -1.1938453 ],\n",
              "        [-1.0260333 , -0.7956422 , -0.5391088 , -1.2479817 ],\n",
              "        [ 0.90098006,  1.8165575 , -1.2170813 , -0.72254014],\n",
              "        [ 0.41922674, -1.2534504 , -0.96284163,  0.0098934 ],\n",
              "        [-1.7177817 , -0.8854085 ,  0.9157073 , -0.21302116],\n",
              "        [ 0.8268642 , -0.97517484, -0.21424694, -0.37224585]],\n",
              "       dtype=float32),\n",
              " array([[ 2.2597716 , -0.62508625,  0.33660576,  0.94931906],\n",
              "        [ 0.4933426 ,  2.0319967 , -0.9769661 , -0.37224585],\n",
              "        [-0.7789803 , -1.2534504 , -1.1182103 , -0.72254014],\n",
              "        [-0.8283909 , -1.1098243 , -1.3300768 , -0.21302116],\n",
              "        [-1.2360283 , -0.7417824 ,  0.05411719, -0.9454547 ],\n",
              "        [ 1.0121539 , -0.5263433 ,  0.9157073 ,  1.4110706 ],\n",
              "        [-1.2854389 , -1.118801  ,  0.73208976,  0.44298455],\n",
              "        [ 0.95039064, -0.3916938 ,  0.44960117,  2.000202  ]],\n",
              "       dtype=float32),\n",
              " array([[ 0.77745354, -0.4724835 ,  0.37897903,  1.7932099 ],\n",
              "        [-1.6683711 , -0.59815633,  0.84508514, -0.58879143],\n",
              "        [ 0.34511083, -0.62508625,  0.23773475,  0.4238776 ],\n",
              "        [ 0.48098996, -0.50839   ,  0.8592096 ,  1.4269931 ],\n",
              "        [ 0.90098006, -0.75075907,  0.13886376,  1.7135975 ],\n",
              "        [ 1.0368592 ,  1.6011183 , -1.37245   , -0.8499199 ],\n",
              "        [-0.6060432 , -0.9841515 , -1.5560676 , -0.30855596],\n",
              "        [ 1.2592069 , -0.5891797 ,  1.3818134 ,  0.9174741 ]],\n",
              "       dtype=float32),\n",
              " array([[ 0.09805783,  1.4036325 , -1.8103074 , -0.62700534],\n",
              "        [ 0.55510587,  1.2240999 , -1.4854455 , -0.16525376],\n",
              "        [-1.1495597 , -0.15830138,  0.94395614, -1.1747383 ],\n",
              "        [-1.5324919 ,  0.30848345, -0.15774924, -0.4454892 ],\n",
              "        [-0.8778015 , -0.6520161 , -1.1182103 ,  0.39203265],\n",
              "        [-0.7789803 , -1.0828944 ,  0.3648546 , -1.0409895 ],\n",
              "        [ 0.9133327 , -0.59815633,  0.83096075,  0.99708647],\n",
              "        [ 0.3327582 ,  1.7447445 , -1.4854455 ,  0.28057536]],\n",
              "       dtype=float32),\n",
              " array([[-1.1866177 ,  1.7626977 , -0.05887824, -0.53147054],\n",
              "        [ 1.4692019 , -0.6699694 ,  0.29423246,  2.9714725 ],\n",
              "        [-0.5936906 ,  0.08406767,  0.23773475, -1.3435165 ],\n",
              "        [ 0.24628963, -0.49941337,  1.1134493 ,  0.9652415 ],\n",
              "        [ 0.06099989,  1.367726  , -0.8498462 , -0.7384626 ],\n",
              "        [-0.98897535,  0.6226655 , -1.1040859 , -0.7543851 ],\n",
              "        [ 1.5186125 , -0.5622498 ,  1.8479196 ,  1.013009  ],\n",
              "        [ 0.06099989,  3.1091924 ,  0.68971646, -1.1683693 ]],\n",
              "       dtype=float32),\n",
              " array([[-0.9766227 , -1.0290346 ,  0.64734316, -0.0920104 ],\n",
              "        [-0.7048644 , -0.72382915,  0.32248133, -1.2575351 ],\n",
              "        [-1.2360283 , -1.2714037 ,  0.7179653 , -1.4931877 ],\n",
              "        [ 0.03629459, -1.289357  , -0.18599808, -1.1301553 ],\n",
              "        [ 1.7039022 ,  1.1253569 ,  1.169947  ,  1.013009  ],\n",
              "        [-1.4336708 ,  0.4969927 , -0.12950037, -0.78623   ],\n",
              "        [ 0.44393203,  0.20076388, -0.20012252,  0.10542821],\n",
              "        [-0.01311601, -0.59815633,  1.2546936 ,  0.7582494 ]],\n",
              "       dtype=float32),\n",
              " array([[ 0.4933426 ,  1.4126091 , -1.4854455 ,  0.0098934 ],\n",
              "        [ 0.20923167,  2.5616179 , -1.5984409 , -0.06971894],\n",
              "        [ 1.6050811 , -0.37374052,  0.05411719,  1.6976751 ],\n",
              "        [ 0.08570518, -0.75075907,  0.1106149 ,  0.8697067 ],\n",
              "        [-0.7789803 , -1.1367542 ,  0.22361033, -0.27671105],\n",
              "        [ 0.690985  , -0.5622498 ,  1.0852004 ,  0.15319562],\n",
              "        [ 1.358028  , -0.28397423,  0.19536147,  0.99708647],\n",
              "        [ 1.716255  , -0.4186237 ,  1.367689  ,  1.72952   ]],\n",
              "       dtype=float32),\n",
              " array([[-1.458376  , -0.777689  ,  1.0145783 , -0.8021525 ],\n",
              "        [ 1.432144  ,  0.15588072, -1.273579  , -0.27671105],\n",
              "        [ 0.19687903,  0.02123125,  0.78858745,  1.3951482 ],\n",
              "        [ 0.8515695 ,  0.8291281 , -1.1182103 , -0.21302116],\n",
              "        [-1.3966128 ,  1.7716744 ,  1.4524356 , -1.1683693 ],\n",
              "        [-1.9030714 ,  1.2600064 ,  0.28010803, -0.58879143],\n",
              "        [ 1.395086  ,  1.5831652 , -1.4289478 , -0.5951604 ],\n",
              "        [-0.96427006, -0.9392683 ,  0.576721  , -1.3849149 ]],\n",
              "       dtype=float32),\n",
              " array([[ 1.1109751 , -0.5891797 ,  1.0145783 ,  0.7582494 ],\n",
              "        [-0.9272121 , -0.54429656,  0.78858745, -0.7543851 ],\n",
              "        [ 0.19687903,  1.1074036 , -1.3159523 ,  0.2646529 ],\n",
              "        [ 1.0615644 , -0.7417824 ,  0.774463  , -1.0728345 ],\n",
              "        [-1.1372072 , -1.0828944 ,  0.1529882 , -0.37224585],\n",
              "        [ 0.13511579, -0.3916938 , -1.8103074 , -1.0250671 ],\n",
              "        [ 1.4815546 , -0.51736665,  0.33660576,  2.239039  ],\n",
              "        [-0.8778015 ,  0.7483384 ,  0.3083569 , -1.0855725 ]],\n",
              "       dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gf_DgkrgMZbf",
        "colab_type": "code",
        "outputId": "506d7c5f-1124-4d66-c5e6-c8b49a9536cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# visualizando os valores do batch\n",
        "X_batches[1] "
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.28334758,  0.8650346 , -1.5560676 , -0.22894363],\n",
              "       [ 0.5056953 ,  1.3497727 ,  0.54847217,  0.9174741 ],\n",
              "       [ 0.690985  , -0.54429656,  0.59084547,  1.1881561 ],\n",
              "       [-1.7054291 , -0.31090412,  0.49197447, -1.2798265 ],\n",
              "       [-0.22311106,  0.92787105, -1.2170813 , -0.19709869],\n",
              "       [ 0.92568535, -0.54429656,  0.4072279 ,  1.8250549 ],\n",
              "       [-0.49486935,  0.11099756, -1.4571966 , -0.16525376],\n",
              "       [ 0.9627433 ,  0.3802965 , -1.3159523 , -0.42001325],\n",
              "       [ 0.7156903 ,  0.21871714, -1.1464592 ,  0.0098934 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVdp2G0TMZbh",
        "colab_type": "text"
      },
      "source": [
        "# Inicio do treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FHkQmG9MZbk",
        "colab_type": "code",
        "outputId": "aca9a4dc-ca0d-47ca-e187-ea78d858555f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# criamos uma sessão para inicializar o treinamento.\n",
        "with tf.Session() as sess:\n",
        "    # inicialização das variaveis.\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    # definimos o numero de épocas\n",
        "    for epoca in range(3000):\n",
        "        # variavel para calculo do erro.\n",
        "        erro_medio = 0.0\n",
        "        batch_total = int(len(X_treinamento) / batch_size)\n",
        "        X_batches = np.array_split(X_treinamento, batch_total)\n",
        "        # separamos batchs para o Y também\n",
        "        y_batches = np.array_split(y_treinamento, batch_total)\n",
        "        # calculamos e ajustamos os pesos para cada posição dos registros que separamos\n",
        "        for i in range(batch_total):\n",
        "            # pegamos os valores dos vetores x_batches e y_batches\n",
        "            X_batch, y_batch = X_batches[i], y_batches[i]\n",
        "            # passamos valores para os placeholders\n",
        "            # rodamos nosso otimizador, e esperamos o valor do erro.            \n",
        "            _, custo = sess.run([otimizador, erro], feed_dict = {xph: X_batch, yph: y_batch})\n",
        "            # calculo do erro médio\n",
        "            erro_medio += custo / batch_total\n",
        "        # exibimos os valores do erro para cada 500 registros.\n",
        "        if epoca % 500 == 0:\n",
        "            print('Época: ' + str((epoca + 1)) + ' erro: ' + str(erro_medio))\n",
        "    # ao final do num. de épocas, temos os valores dos pesos ajustados.\n",
        "    W_final, b_final = sess.run([W, b])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Época: 1 erro: 3.373513380686442\n",
            "Época: 501 erro: 0.052057043643738636\n",
            "Época: 1001 erro: 0.02375864977312929\n",
            "Época: 1501 erro: 0.02333520614300563\n",
            "Época: 2001 erro: 0.0231184438911131\n",
            "Época: 2501 erro: 0.02300269340467504\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tl7GDxrFMZbm",
        "colab_type": "code",
        "outputId": "799057eb-3246-4059-ff09-ec2962032856",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# visualizando o vetor de pesos.\n",
        "W_final"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'oculta': array([[ 0.8230233 , -1.0584353 ,  1.5014167 ,  0.3822117 ],\n",
              "        [ 0.24816044, -0.39402783,  0.60707325,  0.54709375],\n",
              "        [ 1.4088385 , -0.55796814, -0.09997141, -1.9124062 ],\n",
              "        [ 0.03997169, -2.2297235 ,  0.8591039 , -0.06184371]],\n",
              "       dtype=float32), 'saida': array([[ 2.0204747 , -0.8584542 , -1.1295006 ],\n",
              "        [-1.4435753 ,  1.0291214 ,  0.00931376],\n",
              "        [ 0.629079  , -1.4336834 , -1.2419999 ],\n",
              "        [-1.8616393 , -0.41132447,  1.8652508 ]], dtype=float32)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHEgCKpxMZbo",
        "colab_type": "code",
        "outputId": "5dde71cb-d278-4f1e-c939-4500d37c9fa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# visualizando o vetor de bias.\n",
        "b_final"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'oculta': array([-1.6394377 ,  1.3632499 ,  0.47001785,  0.36261082], dtype=float32),\n",
              " 'saida': array([ 1.2646803 ,  1.0326518 , -0.44468436], dtype=float32)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWVnNndXMZbq",
        "colab_type": "text"
      },
      "source": [
        "# Previsões\n",
        "\n",
        "com os valores de pesos ajustados, pordemo fazer algumas previsões."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiA_rLs1MZbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# passamos para a func. previsões, os valores de pesos ajustados.\n",
        "previsoes_teste = funRNA(xph, W_final, b_final)\n",
        "with tf.Session() as sess:\n",
        "    # inicializamos as variaveis.\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    # vamos executar a func. previsões, passando o vetor de teste como um placeholder.\n",
        "    resp = sess.run(previsoes_teste, feed_dict = {xph: X_teste})\n",
        "    # para o retorno da probabilidade de cada saída, excutamos a func. softmax.\n",
        "    probabilidade = sess.run(tf.nn.softmax(resp))\n",
        "    # para facilitar a visualização dos valores, vamos usar a func. argmax que retorna\n",
        "    # o indice de onde esta o maior numero.\n",
        "    resp_final = sess.run(tf.argmax(probabilidade, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk1zA4hJMZbt",
        "colab_type": "code",
        "outputId": "a01798d7-2c31-46ee-f0f0-95b17972aec0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "# visualizamos as previsões em percentual.\n",
        "probabilidade"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.70234079e-06, 9.93215561e-01, 6.77884091e-03],\n",
              "       [5.15369233e-04, 7.48361170e-01, 2.51123458e-01],\n",
              "       [9.70609248e-01, 2.42122263e-03, 2.69694757e-02],\n",
              "       [9.99940634e-01, 1.72910211e-06, 5.75828672e-05],\n",
              "       [9.31665361e-01, 1.39535321e-02, 5.43810539e-02],\n",
              "       [5.17969802e-02, 7.09523201e-01, 2.38679737e-01],\n",
              "       [1.17156897e-02, 8.45008731e-01, 1.43275559e-01],\n",
              "       [9.99898076e-01, 1.46905768e-05, 8.73054378e-05],\n",
              "       [9.62979198e-01, 5.15600992e-03, 3.18647102e-02],\n",
              "       [3.55561674e-02, 7.52828479e-01, 2.11615339e-01],\n",
              "       [9.58272278e-01, 6.39719330e-03, 3.53306383e-02],\n",
              "       [9.99991417e-01, 1.51139534e-06, 7.00020792e-06],\n",
              "       [8.80157022e-05, 2.66911574e-02, 9.73220825e-01],\n",
              "       [9.99318957e-01, 7.23839621e-05, 6.08643342e-04],\n",
              "       [1.35163809e-05, 1.01913558e-03, 9.98967409e-01],\n",
              "       [9.89920139e-01, 1.36298139e-03, 8.71691480e-03],\n",
              "       [5.98733546e-03, 8.82574260e-01, 1.11438371e-01],\n",
              "       [3.51684264e-08, 4.54379051e-06, 9.99995470e-01],\n",
              "       [1.40374005e-02, 8.32898915e-01, 1.53063640e-01],\n",
              "       [9.99814570e-01, 2.56749590e-05, 1.59818970e-04],\n",
              "       [9.97532129e-01, 2.94510595e-04, 2.17327476e-03],\n",
              "       [5.36473453e-05, 1.62458047e-03, 9.98321712e-01],\n",
              "       [1.30413497e-07, 4.00056457e-03, 9.95999336e-01],\n",
              "       [4.02459083e-03, 9.00266707e-01, 9.57086310e-02],\n",
              "       [1.95098677e-04, 4.69991229e-02, 9.52805817e-01],\n",
              "       [2.72945791e-01, 3.92527372e-01, 3.34526896e-01],\n",
              "       [9.08110014e-05, 8.70825946e-01, 1.29083201e-01],\n",
              "       [5.95359073e-04, 9.54369485e-01, 4.50352095e-02],\n",
              "       [9.99745071e-01, 2.47746557e-05, 2.30151622e-04],\n",
              "       [6.06268102e-08, 2.99711217e-04, 9.99700308e-01],\n",
              "       [9.98116255e-01, 2.77418731e-04, 1.60633016e-03],\n",
              "       [2.68137141e-04, 5.52638294e-03, 9.94205534e-01],\n",
              "       [9.99936819e-01, 7.51421567e-06, 5.56768391e-05],\n",
              "       [5.10654820e-04, 9.57144201e-01, 4.23451997e-02],\n",
              "       [9.97730672e-01, 2.68801377e-04, 2.00050278e-03],\n",
              "       [3.70670996e-08, 2.55586766e-03, 9.97444153e-01],\n",
              "       [1.02883459e-05, 5.42543596e-04, 9.99447167e-01],\n",
              "       [9.99846697e-01, 1.42262725e-05, 1.39151889e-04],\n",
              "       [2.71980934e-06, 3.12998146e-02, 9.68697429e-01],\n",
              "       [1.80371657e-01, 4.96059358e-01, 3.23568970e-01],\n",
              "       [6.11641109e-01, 1.36985734e-01, 2.51373142e-01],\n",
              "       [9.99997973e-01, 1.70619018e-07, 1.88861532e-06],\n",
              "       [1.13102584e-03, 7.73564160e-01, 2.25304812e-01],\n",
              "       [3.56083873e-08, 3.39161535e-03, 9.96608377e-01],\n",
              "       [3.25460802e-04, 9.64353263e-01, 3.53212655e-02],\n",
              "       [9.96567249e-01, 1.53795045e-04, 3.27883242e-03],\n",
              "       [2.70536024e-04, 2.32254456e-06, 9.99727070e-01],\n",
              "       [3.32008727e-04, 1.91493324e-04, 9.99476492e-01],\n",
              "       [9.99974966e-01, 3.46960269e-06, 2.15522432e-05],\n",
              "       [1.29351989e-04, 3.31179268e-04, 9.99539495e-01],\n",
              "       [9.97960448e-01, 2.39297806e-04, 1.80031359e-03],\n",
              "       [8.49229946e-06, 3.14013218e-04, 9.99677539e-01],\n",
              "       [9.92886129e-09, 2.61137029e-04, 9.99738872e-01],\n",
              "       [4.44869272e-07, 1.01937674e-01, 8.98061872e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xd4DfZ0DMZbw",
        "colab_type": "code",
        "outputId": "45ac5a05-455d-43b0-aa3e-3f1aebd0306f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# visualizamos a resposta do maior percentual para cada resposta.\n",
        "resp_final"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 2, 0, 1, 2, 1, 0, 0, 2,\n",
              "       2, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 2, 1, 0, 1, 1, 1, 0, 1, 2,\n",
              "       1, 0, 2, 1, 0, 2, 0, 2, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1zPAW6jMZby",
        "colab_type": "text"
      },
      "source": [
        "# Avaliação da rede."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5DS7sT4MZbz",
        "colab_type": "code",
        "outputId": "78e7b883-b49a-4f7c-912d-3f6cb3c8d3a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# para iniciar o calculo precisamos compatibilizar as respostas\n",
        "# para isso utilizaremos a func. argmax no vetor de resultados também.\n",
        "y_teste2 = np.argmax(y_teste, 1)\n",
        "y_teste2"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 2, 0, 2, 0, 1, 2, 1, 0, 0, 2,\n",
              "       2, 1, 2, 1, 1, 1, 0, 2, 0, 2, 0, 1, 0, 2, 2, 0, 2, 1, 1, 0, 1, 2,\n",
              "       1, 0, 2, 2, 0, 2, 0, 2, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Gku3ELRSh_S",
        "colab_type": "text"
      },
      "source": [
        "# Resultado\n",
        "Com 4 entradas: Alcohol Malic acid Color intensity Proline.<br>\n",
        "Conseguimos chegar em uma taxa de acerto de 96,3%, isso quer dizer que no rede neural consegue reconhecer vinhos por esses 4 parametros e com 96% de acerto utilizando a função de ativação de Softmax. Com um otimizador de erro de learning_rate = 0.0001\n",
        "<br>\n",
        "<br>\n",
        "% de outras f de Ativação:\n",
        "\n",
        "> Softmax - Acerto = 96,3% -\n",
        "learning_rate = 0.0001\n",
        "\n",
        "> Sigmoid - Acerto = 68,5% -\n",
        "learning_rate = 0.0001\n",
        "\n",
        "> Sigmoid - Acerto = 50% -\n",
        "learning_rate = 0.000001\n",
        "\n",
        "> Sigmoid - Acerto = 90,7% -\n",
        "learning_rate = 0.01\n",
        "\n",
        "> Softmax - Acerto = 85,15% -\n",
        "learning_rate = 0.01\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4I0mejGMZb1",
        "colab_type": "code",
        "outputId": "b7ce7349-88c1-46cf-a6a2-e9239fa9e3a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# para o calculo de precisão vamos usar a func. accuracy_score do sklearn.\n",
        "from sklearn.metrics import accuracy_score\n",
        "# calculo de precisão da rede\n",
        "taxa_acerto = accuracy_score(y_teste2, resp_final)\n",
        "# valor em %\n",
        "taxa_acerto"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8518518518518519"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    }
  ]
}