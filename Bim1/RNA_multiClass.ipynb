{"cells":[{"cell_type":"markdown","metadata":{"id":"Krufg2DqMZad","colab_type":"text"},"source":["# Exemplo de implementação de rede neural low-level.\n","Base de dados utilizada iris do lib sklearn.\n","\n","Problema multi-classes utilizando a função de ativação SOFTMAX\n"]},{"cell_type":"code","metadata":{"id":"zpZvqV3vMZae","colab_type":"code","colab":{}},"source":["# importação da lib sklearn importando os datasets\n","# repositório: archive.ics.uci.edu/ml/datasets/Iris\n","from sklearn import datasets\n","# vamos usar o exemplo iris()\n","iris = datasets.load_iris()\n","# atributos previsores (4 características)\n","X = iris.data\n","X"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nt3CR3JKMZaj","colab_type":"code","colab":{}},"source":["# atributos das classes\n","y = iris.target\n","y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zxeo_yhOMZan","colab_type":"code","colab":{}},"source":["# padronização dos dados\n","from sklearn.preprocessing import StandardScaler\n","scaler_x = StandardScaler()\n","X = scaler_x.fit_transform(X)\n","X"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i6ToDV9bMmKu","colab_type":"text"},"source":["![alt text](https://drive.google.com/uc?id=1bCs3lSCjjfJet-cQhoRIvgvXshAE--Rz)\n","\n","Como nosso exemplo tem 3 classes como resposta, precisamos de 3 neurônios de saída"]},{"cell_type":"code","metadata":{"id":"ytX0S9K3MZat","colab_type":"code","colab":{}},"source":["# precisamos compatibilizar o numero de registros de saída com a quantidade de classes esperadas.\n","# para isso iremos utilizar o comando OneHotEncoder para que cada resposta tenha 3 atributos, que seja igual \n","# a quantidade de neurônios na camada de saída.\n","from sklearn.preprocessing import OneHotEncoder\n","# passo como parametrao qual coluna quermos fazer a transformação.\n","# instancio um objeto.\n","onehot = OneHotEncoder()\n","y.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"31LgjhJoMZaw","colab_type":"code","colab":{}},"source":["# transformando a resposta em formato de matriz\n","y = y.reshape(-1, 1)\n","y.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZIgZERx4MZaz","colab_type":"code","colab":{}},"source":["onehot.fit(y)\n","y = onehot.transform(y).toarray()\n","y"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TAOp07GjMZa2","colab_type":"text"},"source":["# agora temos as 3 classes representadas por codificação\n","classe 1 -> 1 0 0\n","\n","classe 2 -> 0 1 0\n","\n","classe 3 -> 0 0 1"]},{"cell_type":"code","metadata":{"id":"5awxjDxyMZa3","colab_type":"code","colab":{}},"source":["# divisão da base em treinamento (70%) e teste (30%).\n","from sklearn.model_selection import train_test_split\n","X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(X, y, test_size = 0.3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BZaaN6IAMZa5","colab_type":"code","colab":{}},"source":["# conferindo a quantidade de regitros.\n","X_treinamento.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O7dQp3FFMZa8","colab_type":"code","colab":{}},"source":["# conferindo a quantidade de regitros.\n","X_teste.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XX8IAgBYMZa_","colab_type":"code","colab":{}},"source":["# importação do TensorFlow\n","%tensorflow_version 1.x\n","import tensorflow as tf\n","# importação do NumPy\n","import numpy as np\n","tf.__version__"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nl_2g2NIMZbC","colab_type":"code","colab":{}},"source":["# quantidade dos neurônios\n","# para a entrada o num. de neurônios é a quantidade de atributos.\n","neuronios_entrada = X.shape[1]\n","neuronios_entrada"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S41-gSoRMZbF","colab_type":"code","colab":{}},"source":["# para a camada oculta\n","# podemos criar a quantidade baseado no calculo\n","# (quantidade de atributos previsores + quantidade de classes) / 2\n","# np.ceil arredonda para cima\n","neuronios_oculta = int(np.ceil((X.shape[1] + y.shape[1]) / 2))\n","neuronios_oculta"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6lD0Lja2MZbH","colab_type":"code","colab":{}},"source":["# neurônios na camada de saída que é igual ao num. de classes\n","neuronios_saida = y.shape[1]\n","neuronios_saida"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rHngreLRMZbJ","colab_type":"text"},"source":["![Modelo de RNA](https://drive.google.com/uc?id=1bCs3lSCjjfJet-cQhoRIvgvXshAE--Rz)\n","\n","Modelo da RNA\n","<!-- ![Modelo da RNA](RNA2.png) -->"]},{"cell_type":"code","metadata":{"id":"yaznEQW2MZbK","colab_type":"code","colab":{}},"source":["# criar os pesos, usamos uma estrutura de dados com keys\n","# para a camada oculta precisamos de uma matriz de 4 x 4 = 16 pesos.\n","# para a camada saída precisamos de uma matriz de 4 x 3 = 12 pesos.\n","# os valores do peso são criados com a função RANDOM.\n","W = {'oculta': tf.Variable(tf.random_normal([neuronios_entrada, neuronios_oculta])),\n","     'saida': tf.Variable(tf.random_normal([neuronios_oculta, neuronios_saida]))}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RY-I9MeWMZbO","colab_type":"code","colab":{}},"source":["# pesos para a unidade de bias\n","# para a camada oculta teremos 4 pesos\n","# para a camada saída teremos 3 pesos.\n","b = {'oculta': tf.Variable(tf.random_normal([neuronios_oculta])),\n","     'saida': tf.Variable(tf.random_normal([neuronios_saida]))}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jp5wIyhyMZbQ","colab_type":"text"},"source":["![Modelo da RNA](https://drive.google.com/uc?id=1_-_xgpimyQ-R1TReFQrN0k7c3RjqDE28)\n","\n"]},{"cell_type":"code","metadata":{"id":"NKPmkx6IMZbR","colab_type":"code","colab":{}},"source":["# criamos os places holders para X, com quantidade indefinida de linha e com 4 colunas\n","xph = tf.placeholder('float', [None, neuronios_entrada])\n","# criamos os places holders para Y, com quantidade indefinida de linha e com 3 colunas\n","yph = tf.placeholder('float', [None, neuronios_saida])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zwKXvlm_MZbU","colab_type":"code","colab":{}},"source":["# criamos um função para facilitar na reutilização do códigos para testes.\n","# nesta função faremos os calculos do somatório dos peso, o calculo da função de ativação\n","# para as camadas da nossa rede.\n","def funRNA(x, W, bias):\n","    # somatório da camada oculta\n","    camada_oculta = tf.add(tf.matmul(x, W['oculta']), bias['oculta']) \n","    # calculo func. ativação RELU\n","    camada_oculta_ativacao = tf.nn.relu(camada_oculta) \n","    # somatório da camada de saída.\n","    camada_saida = tf.add(tf.matmul(camada_oculta_ativacao, W['saida']), b['saida']) \n","    # retorno dos valores da camada oculta.\n","    return camada_saida"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZkoGqPDyMZbW","colab_type":"code","colab":{}},"source":["# criamos um modelo que irá enviar como parametros para a func. os valores de pesos e as entradas da rede.\n","# esperamos como saída o calculo dos valores do somatório da camada de saída.\n","modelo = funRNA(xph, W, b)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6kgx-TnfMZbY","colab_type":"code","colab":{}},"source":["# aqui faremos o calculo da função de ativação junto com o calculo do erro.\n","# estamos usando a função SOFTMAX como função de ativação neste modelo.\n","# para que a função faça o calculo do erro, precisamos passar como paramentros os valores\n","# que foram calculados pela rede (modelo) e os valores corretor (yph)\n","# modelo -> respostas que o modelo fez a previsão\n","# yph -> respostas corretas, vetor Y.\n","# func. reduce_mean faz a média do batch inteiro.\n","erro = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = modelo, labels = yph))\n","# vamos criar o otimizados, usando a função ADAM, que é similar ao gradiente de descida.\n","# passamos como parametro o erro, para que seja feita a otimização desse erro.\n","otimizador = tf.train.AdamOptimizer(learning_rate = 0.0001).minimize(erro)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OImgZzQKMZba","colab_type":"code","colab":{}},"source":["# tamanho da atualização dos registros.\n","batch_size = 8\n","batch_total = int(len(X_treinamento) / batch_size)\n","batch_total"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HqzTkyAOMZbc","colab_type":"code","colab":{}},"source":["# separa o vetor treinamento em 13 partes.\n","X_batches = np.array_split(X_treinamento, batch_total)\n","X_batches"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gf_DgkrgMZbf","colab_type":"code","colab":{}},"source":["# visualizando os valores do batch\n","X_batches[1] "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bVdp2G0TMZbh","colab_type":"text"},"source":["# Inicio do treinamento"]},{"cell_type":"code","metadata":{"id":"8FHkQmG9MZbk","colab_type":"code","colab":{}},"source":["# criamos uma sessão para inicializar o treinamento.\n","with tf.Session() as sess:\n","    # inicialização das variaveis.\n","    sess.run(tf.global_variables_initializer())\n","    # definimos o numero de épocas\n","    for epoca in range(3000):\n","        # variavel para calculo do erro.\n","        erro_medio = 0.0\n","        batch_total = int(len(X_treinamento) / batch_size)\n","        X_batches = np.array_split(X_treinamento, batch_total)\n","        # separamos batchs para o Y também\n","        y_batches = np.array_split(y_treinamento, batch_total)\n","        # calculamos e ajustamos os pesos para cada posição dos registros que separamos\n","        for i in range(batch_total):\n","            # pegamos os valores dos vetores x_batches e y_batches\n","            X_batch, y_batch = X_batches[i], y_batches[i]\n","            # passamos valores para os placeholders\n","            # rodamos nosso otimizador, e esperamos o valor do erro.            \n","            _, custo = sess.run([otimizador, erro], feed_dict = {xph: X_batch, yph: y_batch})\n","            # calculo do erro médio\n","            erro_medio += custo / batch_total\n","        # exibimos os valores do erro para cada 500 registros.\n","        if epoca % 500 == 0:\n","            print('Época: ' + str((epoca + 1)) + ' erro: ' + str(erro_medio))\n","    # ao final do num. de épocas, temos os valores dos pesos ajustados.\n","    W_final, b_final = sess.run([W, b])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tl7GDxrFMZbm","colab_type":"code","colab":{}},"source":["# visualizando o vetor de pesos.\n","W_final"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EHEgCKpxMZbo","colab_type":"code","colab":{}},"source":["# visualizando o vetor de bias.\n","b_final"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jWVnNndXMZbq","colab_type":"text"},"source":["# Previsões\n","\n","com os valores de pesos ajustados, pordemo fazer algumas previsões."]},{"cell_type":"code","metadata":{"id":"XiA_rLs1MZbr","colab_type":"code","colab":{}},"source":["# passamos para a func. previsões, os valores de pesos ajustados.\n","previsoes_teste = funRNA(xph, W_final, b_final)\n","with tf.Session() as sess:\n","    # inicializamos as variaveis.\n","    sess.run(tf.global_variables_initializer())\n","    # vamos executar a func. previsões, passando o vetor de teste como um placeholder.\n","    resp = sess.run(previsoes_teste, feed_dict = {xph: X_teste})\n","    # para o retorno da probabilidade de cada saída, excutamos a func. softmax.\n","    probabilidade = sess.run(tf.nn.softmax(resp))\n","    # para facilitar a visualização dos valores, vamos usar a func. argmax que retorna\n","    # o indice de onde esta o maior numero.\n","    resp_final = sess.run(tf.argmax(probabilidade, 1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tk1zA4hJMZbt","colab_type":"code","colab":{}},"source":["# visualizamos as previsões em percentual.\n","probabilidade"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xd4DfZ0DMZbw","colab_type":"code","colab":{}},"source":["# visualizamos a resposta do maior percentual para cada resposta.\n","resp_final"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i1zPAW6jMZby","colab_type":"text"},"source":["# Avaliação da rede."]},{"cell_type":"code","metadata":{"id":"P5DS7sT4MZbz","colab_type":"code","colab":{}},"source":["# para iniciar o calculo precisamos compatibilizar as respostas\n","# para isso utilizaremos a func. argmax no vetor de resultados também.\n","y_teste2 = np.argmax(y_teste, 1)\n","y_teste2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b4I0mejGMZb1","colab_type":"code","colab":{}},"source":["# para o calculo de precisão vamos usar a func. accuracy_score do sklearn.\n","from sklearn.metrics import accuracy_score\n","# calculo de precisão da rede\n","taxa_acerto = accuracy_score(y_teste2, resp_final)\n","# valor em %\n","taxa_acerto"],"execution_count":0,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"RNA_multiClass.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}